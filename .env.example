OPENAI_API_KEY=sk-...
FIRECRAWL_API_KEY=fc-...
# Feedback Processor Theory - Environment Configuration
# Copy this file to .env and fill in your actual values
# NEVER commit .env to version control

# ======================
# API Keys (Required)
# ======================

# OpenAI API Key (required for GPT and embeddings)
OPENAI_API_KEY=sk-proj-...

# NVIDIA NIM API Key (optional - for Llama/Mistral models)
NVAPI_KEY=nvapi-...

# Anthropic API Key (optional - for Claude)
ANTHROPIC_API_KEY=sk-ant-...

# ======================
# Model Configuration
# ======================

# OpenAI Chat Model
# Options: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
OPENAI_CHAT_MODEL=gpt-4o-mini

# OpenAI Embeddings Model
# Options: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
TEXT_EMB_MODEL=text-embedding-3-small

# NVIDIA Model (if using NVAPI)
# Options: meta/llama-3.1-405b-instruct, mistralai/mixtral-8x7b-instruct-v0.1
NV_MODEL=meta/llama-3.1-405b-instruct

# Claude Model (if using Anthropic)
# Options: claude-sonnet-4-5, claude-opus-4, claude-3-5-sonnet-20241022
CLAUDE_MODEL=claude-sonnet-4-5

# ======================
# Server Configuration
# ======================

# Backend WebSocket Server
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8765

# Frontend HTTP Server
FRONTEND_PORT=8000

# ======================
# Feature Flags
# ======================

# Enable real-time embeddings (costs API credits)
ENABLE_EMBEDDINGS=true

# Enable audio transcription with Whisper
ENABLE_AUDIO=true

# Use embedding cache to reduce API calls
USE_EMBEDDING_CACHE=true

# Maximum cache size (number of embeddings)
CACHE_MAX_SIZE=10000

# Demo mode (uses simulated embeddings to save costs)
DEMO_MODE=false

# ======================
# Performance Settings
# ======================

# Maximum concurrent sessions
MAX_SESSIONS=100

# Session timeout in seconds
SESSION_TIMEOUT=3600

# Token batch size for embedding
TOKEN_BATCH_SIZE=10

# Audio chunk size in seconds
AUDIO_CHUNK_DURATION=2.0

# ======================
# Redis Configuration
# ======================

REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# ======================
# Logging
# ======================

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Log format: json, text
LOG_FORMAT=json

# Log file path
LOG_FILE=logs/harmonic-demo.log

# ======================
# Security
# ======================

# CORS allowed origins (comma-separated)
ALLOWED_ORIGINS=http://localhost:8000,http://localhost:3000

# Rate limiting (requests per minute)
RATE_LIMIT_PER_MINUTE=60

# Max message size in bytes
MAX_MESSAGE_SIZE=1048576

# JWT secret for session tokens (generate with: openssl rand -hex 32)
JWT_SECRET=

# ======================
# Monitoring
# ======================

# Enable Prometheus metrics
ENABLE_METRICS=true

# Metrics port
METRICS_PORT=9090

# ======================
# Development
# ======================

# Enable debug mode (verbose logging, no rate limits)
DEBUG=false

# Enable hot reload
HOT_RELOAD=false